{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Managing State \n",
    "\n",
    "So far, we have discussed how to build components in a multi-agent application - agents, teams, termination conditions. In many cases, it is useful to save the state of these components to disk and load them back later. This is particularly useful in a web application where stateless endpoints respond to requests and need to load the state of the application from persistent storage.\n",
    "\n",
    "In this notebook, we will discuss how to save and load the state of agents, teams, and termination conditions. \n",
    " \n",
    "\n",
    "## Saving and Loading Agents\n",
    "\n",
    "We can get the state of an agent by calling {py:meth}`~autogen_agentchat.agents.AssistantAgent.save_state` method on \n",
    "an {py:class}`~autogen_agentchat.agents.AssistantAgent`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# capture magic suppresses install output\n",
    "!poetry add autogen_core autogen_ext autogen_agentchat openai tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In Tanganyika's depths, whispers of ancient tales,  \n",
      "Crystal waters embrace the fish's silken trails,  \n",
      "Nature's timeless mirror, where serenity prevails.  \n"
     ]
    }
   ],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.conditions import MaxMessageTermination\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_core import CancellationToken\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "\n",
    "assistant_agent = AssistantAgent(\n",
    "    name=\"assistant_agent\",\n",
    "    system_message=\"You are a helpful assistant\",\n",
    "    model_client=OpenAIChatCompletionClient(\n",
    "        model=\"gpt-4o-2024-08-06\",\n",
    "        # api_key=\"YOUR_API_KEY\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Use asyncio.run(...) when running in a script.\n",
    "response = await assistant_agent.on_messages(\n",
    "    [TextMessage(content=\"Write a 3 line poem on lake tangayika\", source=\"user\")], CancellationToken()\n",
    ")\n",
    "print(response.chat_message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'AssistantAgentState', 'version': '1.0.0', 'llm_context': {'messages': [{'content': 'Write a 3 line poem on lake tangayika', 'source': 'user', 'type': 'UserMessage'}, {'content': \"In Tanganyika's depths, whispers of ancient tales,  \\nCrystal waters embrace the fish's silken trails,  \\nNature's timeless mirror, where serenity prevails.  \", 'source': 'assistant_agent', 'type': 'AssistantMessage'}]}}\n"
     ]
    }
   ],
   "source": [
    "agent_state = await assistant_agent.save_state()\n",
    "print(agent_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The last line of the previous poem I wrote was:  \n",
      "\"Nature's timeless mirror, where serenity prevails.\"\n"
     ]
    }
   ],
   "source": [
    "new_assistant_agent = AssistantAgent(\n",
    "    name=\"assistant_agent\",\n",
    "    system_message=\"You are a helpful assistant\",\n",
    "    model_client=OpenAIChatCompletionClient(\n",
    "        model=\"gpt-4o-2024-08-06\",\n",
    "    ),\n",
    ")\n",
    "await new_assistant_agent.load_state(agent_state)\n",
    "\n",
    "# Use asyncio.run(...) when running in a script.\n",
    "response = await new_assistant_agent.on_messages(\n",
    "    [TextMessage(content=\"What was the last line of the previous poem you wrote\", source=\"user\")], CancellationToken()\n",
    ")\n",
    "print(response.chat_message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{note}\n",
    "For {py:class}`~autogen_agentchat.agents.AssistantAgent`, its state consists of the model_context.\n",
    "If your write your own custom agent, consider overriding the {py:meth}`~autogen_agentchat.agents.BaseChatAgent.save_state` and {py:meth}`~autogen_agentchat.agents.BaseChatAgent.load_state` methods to customize the behavior. The default implementations save and load an empty state.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and Loading Teams \n",
    "\n",
    "We can get the state of a team by calling `save_state` method on the team and load it back by calling `load_state` method on the team. \n",
    "\n",
    "When we call `save_state` on a team, it saves the state of all the agents in the team.\n",
    "\n",
    "We will begin by creating a simple {py:class}`~autogen_agentchat.teams.RoundRobinGroupChat` team with a single agent and ask it to write a poem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- user ----------\n",
      "Write a beautiful poem 3-line about lake tangayika\n",
      "---------- assistant_agent ----------\n",
      "In Tanganyika's mirror deep and wide,  \n",
      "Whispers of ancient waters glide,  \n",
      "Eternal blue, where earth and sky collide.  \n"
     ]
    }
   ],
   "source": [
    "# Define a team.\n",
    "assistant_agent = AssistantAgent(\n",
    "    name=\"assistant_agent\",\n",
    "    system_message=\"You are a helpful assistant\",\n",
    "    model_client=OpenAIChatCompletionClient(\n",
    "        model=\"gpt-4o-2024-08-06\",\n",
    "    ),\n",
    ")\n",
    "agent_team = RoundRobinGroupChat([assistant_agent], termination_condition=MaxMessageTermination(max_messages=2))\n",
    "\n",
    "# Run the team and stream messages to the console.\n",
    "stream = agent_team.run_stream(task=\"Write a beautiful poem 3-line about lake tangayika\")\n",
    "\n",
    "# Use asyncio.run(...) when running in a script.\n",
    "await Console(stream)\n",
    "\n",
    "# Save the state of the agent team.\n",
    "team_state = await agent_team.save_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we reset the team (simulating instantiation of the team),  and ask the question `What was the last line of the poem you wrote?`, we see that the team is unable to accomplish this as there is no reference to the previous run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- user ----------\n",
      "What was the last line of the poem you wrote?\n",
      "---------- assistant_agent ----------\n",
      "I don't have personal experiences or memories, so I can't recall writing any specific poem. However, I'd be happy to help you create a new poem or assist you with any other request!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(source='user', models_usage=None, content='What was the last line of the poem you wrote?', type='TextMessage'), TextMessage(source='assistant_agent', models_usage=RequestUsage(prompt_tokens=28, completion_tokens=38), content=\"I don't have personal experiences or memories, so I can't recall writing any specific poem. However, I'd be happy to help you create a new poem or assist you with any other request!\", type='TextMessage')], stop_reason='Maximum number of messages 2 reached, current message count: 2')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await agent_team.reset()\n",
    "stream = agent_team.run_stream(task=\"What was the last line of the poem you wrote?\")\n",
    "await Console(stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we load the state of the team and ask the same question. We see that the team is able to accurately return the last line of the poem it wrote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'TeamState', 'version': '1.0.0', 'agent_states': {'group_chat_manager/ffe2a6a2-3271-4897-8b97-4a91ff8e7790': {'type': 'RoundRobinManagerState', 'version': '1.0.0', 'message_thread': [{'source': 'user', 'models_usage': None, 'content': 'Write a beautiful poem 3-line about lake tangayika', 'type': 'TextMessage'}, {'source': 'assistant_agent', 'models_usage': {'prompt_tokens': 29, 'completion_tokens': 30}, 'content': \"In Tanganyika's mirror deep and wide,  \\nWhispers of ancient waters glide,  \\nEternal blue, where earth and sky collide.  \", 'type': 'TextMessage'}], 'current_turn': 0, 'next_speaker_index': 0}, 'collect_output_messages/ffe2a6a2-3271-4897-8b97-4a91ff8e7790': {}, 'assistant_agent/ffe2a6a2-3271-4897-8b97-4a91ff8e7790': {'type': 'ChatAgentContainerState', 'version': '1.0.0', 'agent_state': {'type': 'AssistantAgentState', 'version': '1.0.0', 'llm_context': {'messages': [{'content': 'Write a beautiful poem 3-line about lake tangayika', 'source': 'user', 'type': 'UserMessage'}, {'content': \"In Tanganyika's mirror deep and wide,  \\nWhispers of ancient waters glide,  \\nEternal blue, where earth and sky collide.  \", 'source': 'assistant_agent', 'type': 'AssistantMessage'}]}}, 'message_buffer': []}}, 'team_id': 'ffe2a6a2-3271-4897-8b97-4a91ff8e7790'}\n",
      "---------- user ----------\n",
      "What was the last line of the poem you wrote?\n",
      "---------- assistant_agent ----------\n",
      "The last line of the poem I wrote was:  \n",
      "\"Eternal blue, where earth and sky collide.\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(source='user', models_usage=None, content='What was the last line of the poem you wrote?', type='TextMessage'), TextMessage(source='assistant_agent', models_usage=RequestUsage(prompt_tokens=81, completion_tokens=22), content='The last line of the poem I wrote was:  \\n\"Eternal blue, where earth and sky collide.\"', type='TextMessage')], stop_reason='Maximum number of messages 2 reached, current message count: 2')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(team_state)\n",
    "\n",
    "# Load team state.\n",
    "await agent_team.load_state(team_state)\n",
    "stream = agent_team.run_stream(task=\"What was the last line of the poem you wrote?\")\n",
    "await Console(stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persisting State (File or Database)\n",
    "\n",
    "In many cases, we may want to persist the state of the team to disk (or a database) and load it back later. State is a dictionary that can be serialized to a file or written to a database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'coding/team_state.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m## save state to disk\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcoding/team_state.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      6\u001b[0m     json\u001b[38;5;241m.\u001b[39mdump(team_state, f)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m## load state from disk\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/user-guide-D-RJBqt1-py3.10/lib/python3.10/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'coding/team_state.json'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "## save state to disk\n",
    "\n",
    "with open(\"coding/team_state.json\", \"w\") as f:\n",
    "    json.dump(team_state, f)\n",
    "\n",
    "## load state from disk\n",
    "with open(\"coding/team_state.json\", \"r\") as f:\n",
    "    team_state = json.load(f)\n",
    "\n",
    "new_agent_team = RoundRobinGroupChat([assistant_agent], termination_condition=MaxMessageTermination(max_messages=2))\n",
    "await new_agent_team.load_state(team_state)\n",
    "stream = new_agent_team.run_stream(task=\"What was the last line of the poem you wrote?\")\n",
    "await Console(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
